\babel@toc {naustrian}{}\relax
\babel@toc {naustrian}{}\relax
\babel@toc {english}{}\relax
\babel@toc {naustrian}{}\relax
\babel@toc {naustrian}{}\relax
\babel@toc {naustrian}{}\relax
\babel@toc {english}{}\relax
\babel@toc {naustrian}{}\relax
\babel@toc {naustrian}{}\relax
\addvspace {10pt}
\babel@toc {naustrian}{}\relax
\babel@toc {english}{}\relax
\addvspace {10pt}
\babel@toc {naustrian}{}\relax
\babel@toc {english}{}\relax
\addvspace {10pt}
\addvspace {10pt}
\addvspace {10pt}
\contentsline {table}{\numberline {3.1}{\ignorespaces Perturbation presets and severity levels used in robustness evaluation.}}{9}{table.caption.27}%
\addvspace {10pt}
\addvspace {10pt}
\contentsline {table}{\numberline {5.1}{\ignorespaces Fine-tuning hyperparameters for the single-frame detectors.}}{15}{table.caption.33}%
\contentsline {table}{\numberline {5.2}{\ignorespaces Fine-tuning hyperparameters for the video detectors.}}{15}{table.caption.34}%
\addvspace {10pt}
\contentsline {table}{\numberline {6.1}{\ignorespaces Detection performance of all evaluated video object detection models on the VisDrone2019-VID validation set. (Best results in \textbf {bold} and worst results in \underline {underline} per model.)}}{18}{table.caption.35}%
\contentsline {table}{\numberline {6.2}{\ignorespaces Detection performance of all evaluated video object detection models on the VisDrone2019-VID validation set. (Best results in \textbf {bold} and worst results in \underline {underline} per model.)}}{19}{table.caption.36}%
\babel@toc {english}{}\relax
\addvspace {10pt}
\babel@toc {english}{}\relax
\babel@toc {naustrian}{}\relax
\addvspace {10pt}
\babel@toc {english}{}\relax
